{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"top_10_movies\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+--------+------+---------+\n|user_id|movie_id|rating|timestamp|\n+-------+--------+------+---------+\n|    196|     242|     3|881250949|\n|    186|     302|     3|891717742|\n|     22|     377|     1|878887116|\n|    244|      51|     2|880606923|\n|    166|     346|     1|886397596|\n|    298|     474|     4|884182806|\n|    115|     265|     2|881171488|\n|    253|     465|     5|891628467|\n|    305|     451|     3|886324817|\n|      6|      86|     3|883603013|\n|     62|     257|     2|879372434|\n|    286|    1014|     5|879781125|\n|    200|     222|     5|876042340|\n|    210|      40|     3|891035994|\n|    224|      29|     3|888104457|\n|    303|     785|     3|879485318|\n|    122|     387|     5|879270459|\n|    194|     274|     2|879539794|\n|    291|    1042|     4|874834944|\n|    234|    1184|     2|892079237|\n+-------+--------+------+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\",IntegerType(), True ),\n",
    "    StructField(\"movie_id\",IntegerType(), True ),\n",
    "    StructField(\"rating\",IntegerType(), True ),\n",
    "    StructField(\"timestamp\", LongType(), True)\n",
    "])\n",
    "\n",
    "data = spark.read.csv(\"ml-100k/u.data\", sep=\"\\t\", schema = schema)\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+-----+\n|movie_id|count|\n+--------+-----+\n|50      |583  |\n|258     |509  |\n|100     |508  |\n|181     |507  |\n|294     |485  |\n|286     |481  |\n|288     |478  |\n|1       |452  |\n|300     |431  |\n|121     |429  |\n+--------+-----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, desc\n",
    "movies = data.groupBy(\"movie_id\").agg(count(\"movie_id\").alias(\"count\")).orderBy(desc(\"count\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}